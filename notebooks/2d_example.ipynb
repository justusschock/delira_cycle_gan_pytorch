{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cycle GAN with [`delira`](https://github.com/justusschock/delira)\n",
    "\n",
    "The following example shows the basic usage of the provided cycle-gan implementation with `delira`\n",
    "\n",
    "First we need to download our data. For training, we use the official data and a script thankfully provided by [the original implementation](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash download_cyclegan_dataset.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to import the package, providing the actual cycle GAN implementation and the necessary helper functions and classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cycle_gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This package is based on [`delira`](https://github.com/justusschock/delira) and uses it, to provide a basic data-loading structure and training routine. The following creates a training and a testing dataset from the downloaded images.\n",
    "\n",
    "> **Note**: The Dataset classes come from this package, while the data manager class lives within `delira` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delira.data_loading import BaseDataManager\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "dset_train = cycle_gan.UnPairedDataset(\"./datasets/vangogh2photo/trainA\", \n",
    "                                       \"./datasets/vangogh2photo/trainB\", \n",
    "                                       pool_size=50, \n",
    "                                       pool_prob=0.5, \n",
    "                                       img_size=224, \n",
    "                                       n_channels=3)\n",
    "dset_test = cycle_gan.UnPairedDataset(\"./datasets/vangogh2photo/testA\", \n",
    "                                      \"./datasets/vangogh2photo/testB\", \n",
    "                                      pool_size=50, \n",
    "                                      pool_prob=0.5, \n",
    "                                      img_size=224, \n",
    "                                      n_channels=3)\n",
    "\n",
    "man_train = BaseDataManager(dset_train, \n",
    "                            batch_size=BATCH_SIZE, \n",
    "                            n_process_augmentation=4, \n",
    "                            transforms=None, \n",
    "                            sampler_cls=cycle_gan.UnPairedRandomSampler)\n",
    "man_test = BaseDataManager(dset_test, \n",
    "                           batch_size=BATCH_SIZE, \n",
    "                           n_process_augmentation=4, \n",
    "                           transforms=None, \n",
    "                           sampler_cls=cycle_gan.UnPairedRandomSampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the cycle GAN is a special type of generative adversarial network, it also needs a discriminator.\n",
    "\n",
    "We define our (very simple) discriminator without any fancy stuff as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class Conv2dRelu(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Block holding one Conv2d and one ReLU layer\n",
    "    \"\"\"\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        *args :\n",
    "            positional arguments (passed to Conv2d)\n",
    "        **kwargs :\n",
    "            keyword arguments (passed to Conv2d)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self._conv = torch.nn.Conv2d(*args, **kwargs)\n",
    "        self._relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, input_batch):\n",
    "        \"\"\"\n",
    "        Forward batch though layers\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_batch : :class:`torch.Tensor`\n",
    "            input batch\n",
    "        Returns\n",
    "        -------\n",
    "        :class:`torch.Tensor`\n",
    "            result\n",
    "        \"\"\"\n",
    "        return self._relu(self._conv(input_batch))\n",
    "\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = self._build_model(in_channels, 1, torch.nn.InstanceNorm2d, 0.)\n",
    "        self.sigm = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_tensor):\n",
    "        return self.sigm(self.model(input_tensor).view(input_tensor.size(0), -1))\n",
    "    \n",
    "    @staticmethod\n",
    "    def _build_model(in_channels, n_outputs, norm_class, p_dropout):\n",
    "        \"\"\"\n",
    "        Build the actual model structure\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_channels : int\n",
    "            number of input channels\n",
    "        out_params : int\n",
    "            number of outputs\n",
    "        norm_class : Any\n",
    "            class implementing a normalization\n",
    "        p_dropout : float\n",
    "            dropout probability\n",
    "        Returns\n",
    "        -------\n",
    "        :class:`torch.nn.Module`\n",
    "            ensembled model\n",
    "        \"\"\"\n",
    "        model = torch.nn.Sequential()\n",
    "\n",
    "        model.add_module(\"conv_1\", Conv2dRelu(in_channels, 64, (7, 1)))\n",
    "        model.add_module(\"conv_2\", Conv2dRelu(64, 64, (1, 7)))\n",
    "\n",
    "        model.add_module(\"down_conv_1\", Conv2dRelu(64, 128, (7, 7), stride=2))\n",
    "        if norm_class is not None:\n",
    "            model.add_module(\"norm_1\", norm_class(128))\n",
    "        if p_dropout:\n",
    "            model.add_module(\"dropout_1\", torch.nn.Dropout2d(p_dropout))\n",
    "\n",
    "        model.add_module(\"conv_3\", Conv2dRelu(128, 128, (7, 1)))\n",
    "        model.add_module(\"conv_4\", Conv2dRelu(128, 128, (1, 7)))\n",
    "\n",
    "        model.add_module(\"down_conv_2\", Conv2dRelu(128, 256, (7, 7), stride=2))\n",
    "        if norm_class is not None:\n",
    "            model.add_module(\"norm_2\", norm_class(256))\n",
    "        if p_dropout:\n",
    "            model.add_module(\"dropout_2\", torch.nn.Dropout2d(p_dropout))\n",
    "\n",
    "        model.add_module(\"conv_5\", Conv2dRelu(256, 256, (5, 1)))\n",
    "        model.add_module(\"conv_6\", Conv2dRelu(256, 256, (1, 5)))\n",
    "\n",
    "        model.add_module(\"down_conv_3\", Conv2dRelu(256, 256, (5, 5), stride=2))\n",
    "        if norm_class is not None:\n",
    "            model.add_module(\"norm_3\", norm_class(256))\n",
    "        if p_dropout:\n",
    "            model.add_module(\"dropout_3\", torch.nn.Dropout2d(p_dropout))\n",
    "\n",
    "        model.add_module(\"conv_7\", Conv2dRelu(256, 256, (5, 1)))\n",
    "        model.add_module(\"conv_8\", Conv2dRelu(256, 256, (1, 5)))\n",
    "\n",
    "        model.add_module(\"down_conv_4\", Conv2dRelu(256, 128, (5, 5), stride=2))\n",
    "        if norm_class is not None:\n",
    "            model.add_module(\"norm_4\", norm_class(128))\n",
    "        if p_dropout:\n",
    "            model.add_module(\"dropout_4\", torch.nn.Dropout2d(p_dropout))\n",
    "\n",
    "        model.add_module(\"conv_9\", Conv2dRelu(128, 128, (3, 1)))\n",
    "        model.add_module(\"conv_10\", Conv2dRelu(128, 128, (1, 3)))\n",
    "        model.add_module(\"conv_11\", Conv2dRelu(128, 128, (3, 1)))\n",
    "        model.add_module(\"conv_12\", Conv2dRelu(128, 128, (1, 3)))\n",
    "\n",
    "        model.add_module(\"final_conv\", torch.nn.Conv2d(128, n_outputs,\n",
    "                                                       (2, 2)))\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have defined a discriminator for images of size 224x224 pixels, we need to take care of our generator models. For simplicity, we don't define them by ourself, but use an already available U-Net in this example (`UNet2dPyTorch`). \n",
    "\n",
    "Now we need to define our training and model arguments using the `Parameters` class from `delira`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delira.training import Parameters\n",
    "from delira.models.segmentation import UNet2dPyTorch\n",
    "\n",
    "params = Parameters(\n",
    "    fixed_params={\n",
    "        \"training\":{\n",
    "            \"num_epochs\": 100,\n",
    "            \"losses\": {\n",
    "                \"discr\": cycle_gan.DiscriminatorLoss(),\n",
    "                \"adv\": cycle_gan.AdversarialLoss(),\n",
    "                \"cycle\": cycle_gan.CycleLoss()\n",
    "            },\n",
    "            \"optimizer_cls\":{\n",
    "                \"gen\": torch.optim.Adam,\n",
    "                \"discr\": torch.optim.SGD\n",
    "            },\n",
    "            \"optimizer_params\":{\n",
    "                \"discr\": {\"lr\": 1e-3},\n",
    "                \"gen\": {}\n",
    "            }\n",
    "        }, \n",
    "        \"model\":\n",
    "        {\n",
    "            \"generator_cls\": UNet2dPyTorch, \n",
    "            \"gen_kwargs\":\n",
    "            {\n",
    "                \"domain_a\":{}, \n",
    "                \"domain_b\":{}, \n",
    "                \"shared\":{\"in_channels\":3, \"num_classes\":3}\n",
    "            }, \n",
    "            \"discriminator_cls\": Discriminator, \n",
    "            \"discr_kwargs\":\n",
    "            {\n",
    "                \"domain_a\":{}, \n",
    "                \"domain_b\":{}, \n",
    "                \"shared\":{\"in_channels\":3}\n",
    "            },\n",
    "            \"img_logging_freq\": 100\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally! Now, we can start our training using the `PyTorchExperiment`.\n",
    "\n",
    "We just do a few minor specifications here:\n",
    "\n",
    "* set the usable GPUs to the first available GPU if any GPUs have been detected (else specify the usable GPUs to be empty, which causes a training on CPU)\n",
    "* use the `create_optimizers_cycle_gan` to automatically create optimizers for our cycle GAN\n",
    "* use the `CycleGAN` class as our network, which defines the training and prediction behavior.\n",
    "\n",
    "Now let's start training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delira.training import PyTorchExperiment\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_ids = [0]\n",
    "else:\n",
    "    gpu_ids = []\n",
    "\n",
    "exp = PyTorchExperiment(params, \n",
    "                        cycle_gan.CycleGAN, \n",
    "                        optim_builder=cycle_gan.create_optimizers_cycle_gan, \n",
    "                        gpu_ids=gpu_ids)\n",
    "exp.run(man_train, man_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
